{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "price = []\n",
    "percent = []\n",
    "amount = []\n",
    "tprice = []\n",
    "rate = []\n",
    "\n",
    "\n",
    "url = 'https://finance.naver.com/sise/sise_index_day.nhn'\n",
    "for i in range(650):\n",
    "    param = {'code':'KOSPI', 'page':i}\n",
    "    request = requests.get(url,param)\n",
    "\n",
    "    parsing = BeautifulSoup(request.content, 'lxml')\n",
    "\n",
    "    tag_date = parsing.select('td.date')\n",
    "    tag_total = parsing.select('td.number_1')\n",
    "    tag_rate = parsing.select('td.rate_down')\n",
    "    tag_alt = parsing.select('img')\n",
    "    \n",
    "    for d in tag_date:\n",
    "        d_t = d.text\n",
    "        this_date=dt.datetime.strptime(d_t,\"%Y.%m.%d\").date()\n",
    "        date.append(this_date)\n",
    "\n",
    "\n",
    "    for t in range(len(tag_total)):\n",
    "            if t%4==0:\n",
    "                price.append(float(tag_total[t].text.replace(',', '').strip()))\n",
    "    #         elif t%4==1:\n",
    "    #             p = tag_total[t].text\n",
    "    #             percent.append(float(re.findall(\"[0-9]+\",p)[1].strip()))\n",
    "            elif t%4==2:\n",
    "                amount.append(float(tag_total[t].text.replace(',', '').strip()))\n",
    "            elif t%4==3:\n",
    "                tprice.append(float(tag_total[t].text.replace(',', '').strip()))\n",
    "                \n",
    "   \n",
    "\n",
    "    for t in range(len(tag_rate)):\n",
    "        if tag_alt[t]['alt'] == '하락':\n",
    "            rate.append(-float(tag_rate[t].text.strip()))\n",
    "\n",
    "        else:\n",
    "            rate.append(float(tag_rate[t].text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kospi_data = pd.DataFrame({'price':price, 'amount':amount, 'tprice':tprice, 'rate':rate}, index=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_node = 300\n",
    "h2_node = 200\n",
    "h3_node = 100\n",
    "epoch = 10\n",
    "a = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0705 08:57:12.431466  3432 deprecation.py:506] From <ipython-input-20-c4b3584aa6f5>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1971549e+19\n",
      "-835464038400.0\n"
     ]
    }
   ],
   "source": [
    "kospi_data = kospi_data.sort_index()\n",
    "kospi_data.dropna()\n",
    "kospi_data = kospi_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "inputX = []\n",
    "outputY = []\n",
    "\n",
    "for i in range(len(kospi_data)):\n",
    "    inputX.append(list(kospi_data.iloc[i]))\n",
    "    tempY = []\n",
    "    tempY.append(kospi_data.iloc[i][0])\n",
    "    \n",
    "    outputY.append(tempY)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 4], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name = 'y')\n",
    "\n",
    "testx = inputX[-1:]\n",
    "\n",
    "\n",
    "\n",
    "W_h1 = tf.Variable(tf.truncated_normal([4, h1_node]), dtype=tf.float32, name='W_h1')\n",
    "B_h1 = tf.Variable(tf.zeros([h1_node]), dtype=tf.float32, name='B_h1')\n",
    "\n",
    "# Hidden layer의 출력값\n",
    "H1 = tf.nn.relu(tf.matmul(x, W_h1) + B_h1, name='H1')\n",
    "H1 = tf.nn.dropout(H1,0.7)\n",
    "\n",
    "W_h2 = tf.Variable(tf.truncated_normal([h1_node, h2_node]), dtype=tf.float32, name='W_h2')\n",
    "B_h2 = tf.Variable(tf.zeros([h2_node]), dtype=tf.float32, name='B_h2')\n",
    "\n",
    "# Hidden layer의 출력값\n",
    "H2 = tf.nn.relu(tf.matmul(H1, W_h2) + B_h2, name='H2')\n",
    "H2 = tf.nn.dropout(H2,0.7)\n",
    "\n",
    "\n",
    "W_h3 = tf.Variable(tf.truncated_normal([h2_node, h3_node]), dtype=tf.float32, name='W_h3')\n",
    "B_h3 = tf.Variable(tf.zeros([h3_node]), dtype=tf.float32, name='B_h3')\n",
    "\n",
    "# Hidden layer의 출력값\n",
    "H3 = tf.nn.relu(tf.matmul(H2, W_h3) + B_h3, name='H3')\n",
    "H3 = tf.nn.dropout(H3,0.7)\n",
    "\n",
    "\n",
    "W_o = tf.Variable(tf.truncated_normal([h3_node, 1]), dtype=tf.float32, name='W_o')\n",
    "B_o = tf.Variable(tf.zeros([1]), dtype=tf.float32, name='B_o')\n",
    "\n",
    "# Output layer의 출력값\n",
    "predY = tf.add(tf.matmul(H3, W_o), B_o, name='predY')\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(predY, y)))\n",
    "optimize = tf.train.AdamOptimizer(a).minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "\n",
    "    for i in range(epoch):\n",
    "        \n",
    "        sess.run(optimize, feed_dict={x:inputX[:-1], y:outputY[1:]})\n",
    "        cost = sess.run(loss, feed_dict={x:inputX[:-1], y:outputY[1:]})\n",
    "        if i % 1000 == 0:\n",
    "            print(cost)\n",
    "        \n",
    "        \n",
    "        close = sess.run(predY, feed_dict={x:testx})\n",
    "    print(close[0][0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "n_features = 6\n",
    "hidden_size = 6\n",
    "len_sequence = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\n",
    "    tf.float32, [None, len_sequence, n_features])  # X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, len_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)#초기값 주는 것 \n",
    "outputs, _states = tf.nn.dynamic_rnn(\n",
    "    cell, X, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(\n",
    "    inputs=X_for_fc, num_outputs=num_classes, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.reshape(outputs, \n",
    "                     [batch_size, len_sequence, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, len_sequence])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "cost = tf.reduce_mean(sequence_loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epoches):\n",
    "        l, _ = sess.run([cost, optimizer], \n",
    "                        feed_dict={X: X_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: X_one_hot})\n",
    "        print(\"{}epoch-> loss:{}\".format(i, l))\n",
    "\n",
    "        # 1 2 3 4 5 3 -> r o n m a n\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
